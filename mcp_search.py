"""
MCP (Model Context Protocol) æœç´¢å¢å¼ºæ¨¡å—
æ™ºèƒ½åˆ¤æ–­å¹¶æ‰§è¡Œç½‘ç»œæœç´¢ï¼Œä¸ºè§’è‰²å¯¹è¯æä¾›çœŸå®èƒŒæ™¯èµ„æ–™
"""
import re
import json
from typing import List, Dict, Optional
try:
    from ddgs import DDGS  # æ–°ç‰ˆæœ¬çš„åŒ…å
except ImportError:
    try:
        from duckduckgo_search import DDGS  # å‘åå…¼å®¹æ—§ç‰ˆæœ¬
    except ImportError:
        raise ImportError("è¯·å®‰è£…æœç´¢åŒ…: pip install ddgs")
import requests
from bs4 import BeautifulSoup
from openai import OpenAI


class MCPSearchEngine:
    """MCPæœç´¢å¼•æ“ - æ™ºèƒ½åˆ¤æ–­å¹¶æ‰§è¡Œç½‘ç»œæœç´¢"""
    
    def __init__(self, client: OpenAI):
        self.client = client
        self.ddgs = DDGS()
        
    def should_search(self, user_message: str, character_name: str) -> Dict:
        """
        ä½¿ç”¨GPTåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œç½‘ç»œæœç´¢
        
        å‚æ•°:
            user_message: ç”¨æˆ·çš„é—®é¢˜
            character_name: å½“å‰è§’è‰²åç§°
            
        è¿”å›:
            {
                "need_search": bool,
                "search_query": str,
                "reason": str
            }
        """
        decision_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æœç´¢ç­–ç•¥åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢ï¼Œå¹¶ç”Ÿæˆæœ€ä¼˜æœç´¢è¯ã€‚

è§’è‰²ï¼š{character_name}
ç”¨æˆ·é—®é¢˜ï¼š{user_message}

**éœ€è¦æœç´¢çš„æƒ…å†µï¼š**
1. æ¶‰åŠå…·ä½“çš„å†å²äº‹ä»¶ã€æ•…äº‹æƒ…èŠ‚ç»†èŠ‚
2. æåˆ°åŸè‘—ä¸­çš„å…·ä½“åœºæ™¯ã€å¯¹è¯ã€å°è¯
3. è¯¢é—®è§’è‰²èƒŒæ™¯æ•…äº‹çš„è¯¦ç»†å†…å®¹ï¼ˆå¦‚ç§°å·ç”±æ¥ã€ç»å†ã€å…³ç³»ç­‰ï¼‰
4. éœ€è¦å¼•ç”¨åŸä½œå†…å®¹çš„é—®é¢˜
5. è¯¢é—®å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ã€ä¸“ä¸šçŸ¥è¯†
6. éœ€è¦çœŸå®æ•°æ®ã€äº‹å®æ ¸æŸ¥çš„é—®é¢˜

**æœç´¢è¯ç”ŸæˆåŸåˆ™ï¼š**
1. ä½¿ç”¨ç²¾ç¡®çš„å…³é”®è¯ç»„åˆï¼ˆ2-4ä¸ªè¯ï¼‰
2. ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡ï¼ŒåŒ…å«æ ¸å¿ƒæ¦‚å¿µ
3. é¿å…å¤ªå®½æ³›ï¼ˆå¦‚åªæœ"å­™æ‚Ÿç©º"ï¼‰ï¼Œè¦å…·ä½“ï¼ˆå¦‚"å­™æ‚Ÿç©º é½å¤©å¤§åœ£ ç§°å·ç”±æ¥"ï¼‰
4. å¦‚æœæ˜¯è§’è‰²ç›¸å…³ï¼ŒåŠ ä¸Šä½œå“åï¼ˆå¦‚"è¥¿æ¸¸è®° å­™æ‚Ÿç©º å¤§é—¹å¤©å®«"ï¼‰
5. å¦‚æœæ˜¯æŠ€æœ¯é—®é¢˜ï¼ŒåŠ ä¸Šå…³é”®æœ¯è¯­

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "need_search": true/false,
    "search_query": "ç²¾ç¡®çš„æœç´¢å…³é”®è¯ç»„åˆ",
    "reason": "åˆ¤æ–­ç†ç”±ï¼ˆä¸ºä»€ä¹ˆéœ€è¦/ä¸éœ€è¦æœç´¢ï¼‰"
}}"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹åšåˆ¤æ–­
                messages=[{"role": "user", "content": decision_prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            print(f"MCPå†³ç­–å¤±è´¥: {e}")
            return {"need_search": False, "search_query": "", "reason": "å†³ç­–å¤±è´¥"}
    
    def fetch_webpage_content(self, url: str, max_length: int = 3000) -> str:
        """
        æŠ“å–ç½‘é¡µå…¨æ–‡å†…å®¹
        
        å‚æ•°:
            url: ç½‘é¡µURL
            max_length: æœ€å¤§å­—ç¬¦é•¿åº¦
            
        è¿”å›:
            ç½‘é¡µæ–‡æœ¬å†…å®¹
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=5)
            response.encoding = response.apparent_encoding
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
            for script in soup(['script', 'style', 'nav', 'footer', 'header']):
                script.decompose()
            
            # æå–æ–‡æœ¬
            text = soup.get_text(separator='\n', strip=True)
            
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            text = '\n'.join(lines)
            
            # é™åˆ¶é•¿åº¦
            if len(text) > max_length:
                text = text[:max_length] + "..."
                
            return text
            
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•æŠ“å–ç½‘é¡µ {url}: {e}")
            return ""
    
    def search_web(self, query: str, max_results: int = 8) -> List[Dict]:
        """
        ä½¿ç”¨DuckDuckGoæœç´¢ç½‘ç»œå†…å®¹å¹¶æŠ“å–ç½‘é¡µå…¨æ–‡
        
        å‚æ•°:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°ï¼ˆå¢åŠ åˆ°8ï¼‰
            
        è¿”å›:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            results = []
            print(f"ğŸ” å¼€å§‹æœç´¢: {query}")
            
            # å°è¯•å¤šç§æœç´¢ç­–ç•¥
            search_strategies = [
                {'region': None, 'safesearch': 'moderate'},  # å…ˆä¸æŒ‡å®šregion
                {'region': 'wt-wt', 'safesearch': 'moderate'},  # å…¨çƒ
                {'region': 'cn-zh', 'safesearch': 'off'},  # ä¸­å›½åŒºï¼Œå…³é—­å®‰å…¨æœç´¢
            ]
            
            for i, strategy in enumerate(search_strategies):
                try:
                    print(f"  ç­–ç•¥ {i+1}: region={strategy['region']}, safesearch={strategy['safesearch']}")
                    
                    search_params = {
                        'query': query,  # æ”¹ä¸º 'query' è€Œä¸æ˜¯ 'keywords'
                        'max_results': max_results,
                        'safesearch': strategy['safesearch']
                    }
                    if strategy['region']:
                        search_params['region'] = strategy['region']
                    
                    # æ³¨æ„ï¼šæ–°ç‰ˆddgsåŒ…çš„APIå¯èƒ½æœ‰å˜åŒ–
                    search_results = self.ddgs.text(**search_params)
                    
                    # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºåˆ—è¡¨
                    search_results_list = list(search_results) if search_results else []
                    
                    if search_results_list:
                        for r in search_results_list:
                            url = r.get('href', '')
                            title = r.get('title', '')
                            snippet = r.get('body', '')
                            
                            # å°è¯•æŠ“å–ç½‘é¡µå…¨æ–‡
                            print(f"  ğŸ“„ æŠ“å–ç½‘é¡µ: {title[:50]}...")
                            full_content = self.fetch_webpage_content(url)
                            
                            results.append({
                                'title': title,
                                'snippet': snippet,
                                'full_content': full_content if full_content else snippet,
                                'url': url
                            })
                        print(f"  âœ… æˆåŠŸï¼æ‰¾åˆ° {len(results)} æ¡ç»“æœï¼Œå·²æŠ“å–ç½‘é¡µå…¨æ–‡")
                        break  # æˆåŠŸå°±é€€å‡º
                    else:
                        print(f"  âŒ ç­–ç•¥ {i+1} è¿”å›ç©ºç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥")
                        
                except Exception as strategy_error:
                    print(f"  âŒ ç­–ç•¥ {i+1} å¤±è´¥: {strategy_error}")
                    continue
            
            if not results:
                print("âš ï¸ æ‰€æœ‰æœç´¢ç­–ç•¥éƒ½æœªèƒ½æ‰¾åˆ°ç»“æœ")
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def summarize_search_results(self, query: str, results: List[Dict]) -> str:
        """
        ä½¿ç”¨GPTæ€»ç»“æœç´¢ç»“æœï¼ˆä½¿ç”¨ç½‘é¡µå…¨æ–‡ï¼‰
        
        å‚æ•°:
            query: æœç´¢å…³é”®è¯
            results: æœç´¢ç»“æœåˆ—è¡¨
            
        è¿”å›:
            æ€»ç»“æ–‡æœ¬
        """
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        
        # æ„å»ºæœç´¢ç»“æœæ–‡æœ¬ - ä½¿ç”¨å…¨æ–‡å†…å®¹ï¼Œå¢åŠ åˆ°å‰5ä¸ªç»“æœ
        results_text = "\n\n" + "="*50 + "\n\n".join([
            f"ã€æ¥æº {i+1}ã€‘{r['title']}\nç½‘å€ï¼š{r['url']}\n\nå†…å®¹æ‘˜è¦ï¼š\n{r['full_content'][:1500]}"  # ä½¿ç”¨å…¨æ–‡ï¼Œæ¯ä¸ªæºæœ€å¤š1500å­—
            for i, r in enumerate(results[:5])  # å¢åŠ åˆ°5ä¸ªç»“æœ
        ])
        
        summary_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹å…³äº"{query}"çš„ç½‘é¡µå†…å®¹ï¼Œæå–æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚

{results_text}

è¦æ±‚ï¼š
1. **æ·±åº¦æå–**ï¼šä»ç½‘é¡µå…¨æ–‡ä¸­æå–è¯¦ç»†çš„äº‹å®ä¿¡æ¯ï¼ŒåŒ…æ‹¬èƒŒæ™¯ã€ç»†èŠ‚ã€æ•°æ®ç­‰
2. **ç»“æ„åŒ–è¾“å‡º**ï¼šç”¨æ¸…æ™°çš„æ®µè½ç»„ç»‡ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
   - æ ¸å¿ƒäº‹å®ï¼ˆæ˜¯ä»€ä¹ˆï¼‰
   - èƒŒæ™¯ä¿¡æ¯ï¼ˆä¸ºä»€ä¹ˆã€æ€ä¹ˆæ¥çš„ï¼‰
   - ç›¸å…³ç»†èŠ‚ï¼ˆå…·ä½“æƒ…å†µã€æ•°æ®ã€ä¾‹å­ï¼‰
3. **ä¿æŒå‡†ç¡®**ï¼šåªä½¿ç”¨æœç´¢ç»“æœä¸­çš„ä¿¡æ¯ï¼Œä¸æ·»åŠ æ¨æµ‹
4. **ä¿¡æ¯ä¸°å¯Œ**ï¼šè¾“å‡ºåº”è¯¥æ˜¯è¯¦ç»†çš„ï¼ˆ200-400å­—ï¼‰ï¼Œè€Œä¸æ˜¯ç®€å•æ¦‚æ‹¬
5. **å»é‡åˆå¹¶**ï¼šå¦‚æœå¤šä¸ªæ¥æºæœ‰ç›¸åŒä¿¡æ¯ï¼Œåˆå¹¶ååªè¯´ä¸€æ¬¡
6. **ä¿æŒä¸­æ–‡**ï¼šå…¨éƒ¨ä½¿ç”¨ä¸­æ–‡è¾“å‡º

è¯·æä¾›è¯¦ç»†çš„æ€»ç»“ï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.3,
                max_tokens=1000  # å¢åŠ tokené™åˆ¶ï¼Œå…è®¸æ›´è¯¦ç»†çš„æ€»ç»“
            )
            
            summary = response.choices[0].message.content
            print(f"  ğŸ“ æ€»ç»“å®Œæˆ ({len(summary)} å­—)")
            return summary
            
        except Exception as e:
            print(f"æ€»ç»“å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šè¿”å›å‰5ä¸ªç»“æœçš„å…¨æ–‡æ‘˜è¦
            return "\n\n".join([
                f"ã€{r['title']}ã€‘\n{r['full_content'][:300]}"
                for r in results[:5]
            ])
    
    def enhance_context(self, 
                       user_message: str, 
                       character_name: str,
                       search_results_summary: str) -> str:
        """
        ç”Ÿæˆå¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        å‚æ•°:
            user_message: ç”¨æˆ·é—®é¢˜
            character_name: è§’è‰²åç§°
            search_results_summary: æœç´¢ç»“æœæ€»ç»“
            
        è¿”å›:
            å¢å¼ºçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        enhanced_context = f"""
ã€ğŸ” MCPèƒŒæ™¯çŸ¥è¯†å¢å¼ºã€‘
ç”¨æˆ·è¯¢é—®ï¼š{user_message}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š ç›¸å…³çœŸå®èµ„æ–™ï¼ˆæ¥è‡ªç½‘ç»œæœç´¢å¹¶ç»AIæå–ï¼‰ï¼š

{search_results_summary}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**é‡è¦æŒ‡ç¤ºï¼š**
1. **ä¼˜å…ˆä½¿ç”¨çœŸå®èµ„æ–™**ï¼šä»¥ä¸Šæœç´¢ç»“æœæ˜¯ä»å¯é æ¥æºæå–çš„çœŸå®ä¿¡æ¯ï¼Œè¯·å°†å…¶ä½œä¸ºå›ç­”çš„ä¸»è¦ä¾æ®
2. **èå…¥è§’è‰²äººæ ¼**ï¼šç”¨{character_name}çš„å£å»ã€è¯­è¨€é£æ ¼ã€æ€§æ ¼ç‰¹ç‚¹æ¥è¡¨è¾¾è¿™äº›ä¿¡æ¯
3. **è¯¦ç»†ä¸”ç”ŸåŠ¨**ï¼šåŸºäºè¿™äº›è¯¦å®çš„èƒŒæ™¯èµ„æ–™ï¼Œç»™å‡ºä¸°å¯Œã€å…·ä½“ã€æœ‰ç»†èŠ‚çš„å›ç­”
4. **ç¬¬ä¸€äººç§°è§†è§’**ï¼šå¦‚æœæ˜¯è§’è‰²è‡ªèº«çš„äº‹æƒ…ï¼Œç”¨ç¬¬ä¸€äººç§°è®²è¿°ï¼ˆ"æˆ‘å½“æ—¶..."ï¼‰
5. **è‡ªç„¶å¼•ç”¨**ï¼šå°†èƒŒæ™¯çŸ¥è¯†è‡ªç„¶åœ°èå…¥å¯¹è¯ä¸­ï¼Œå°±åƒè§’è‰²åœ¨å›å¿†æˆ–è®²è¿°è‡ªå·±çš„ç»å†
6. **ä¿æŒçœŸå®æ€§**ï¼šä¸è¦ç¼–é€ æœç´¢ç»“æœä¸­æ²¡æœ‰çš„ä¿¡æ¯ï¼Œå¦‚æœæŸäº›ç»†èŠ‚ä¸ç¡®å®šï¼Œå¯ä»¥è¯´"æˆ‘è®°å¾—å¤§æ¦‚æ˜¯..."

è¯·ç°åœ¨ä»¥{character_name}çš„èº«ä»½ï¼ŒåŸºäºä¸Šè¿°çœŸå®èµ„æ–™ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
        return enhanced_context


class MCPChatManager:
    """æ•´åˆMCPæœç´¢çš„å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        self.search_engine = MCPSearchEngine(openai_client)
        self.search_cache = {}  # ç¼“å­˜æœç´¢ç»“æœ
    
    def chat_with_mcp(self, 
                      user_message: str,
                      character: Dict,
                      system_prompt: str,
                      conversation_history: List[Dict],
                      enable_search: bool = True,
                      model: str = "gpt-4o-ca",
                      temperature: float = 0.8,
                      max_tokens: int = 2000) -> Dict:
        """
        å¸¦MCPæœç´¢å¢å¼ºçš„å¯¹è¯
        
        å‚æ•°:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            character: è§’è‰²ä¿¡æ¯å­—å…¸
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            conversation_history: å¯¹è¯å†å²
            enable_search: æ˜¯å¦å¯ç”¨æœç´¢
            model: ä½¿ç”¨çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        è¿”å›:
            {
                "response": str,
                "tokens_used": int,
                "cost": float,
                "search_performed": bool,
                "search_query": str,
                "search_summary": str,
                "search_results": List[Dict]
            }
        """
        result = {
            "response": "",
            "tokens_used": 0,
            "cost": 0.0,
            "search_performed": False,
            "search_query": "",
            "search_summary": "",
            "search_results": []
        }
        
        # 1. MCPå†³ç­–ï¼šæ˜¯å¦éœ€è¦æœç´¢
        if enable_search:
            decision = self.search_engine.should_search(
                user_message, 
                character['name']
            )
            
            if decision['need_search']:
                search_query = decision['search_query']
                print(f"ğŸ” MCPè§¦å‘æœç´¢: {search_query}")
                
                # æ£€æŸ¥ç¼“å­˜
                if search_query in self.search_cache:
                    search_summary = self.search_cache[search_query]['summary']
                    search_results = self.search_cache[search_query]['results']
                    print("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æœç´¢ç»“æœ")
                else:
                    # 2. æ‰§è¡Œæœç´¢ï¼ˆå¢åŠ æœç´¢ç»“æœæ•°é‡ï¼‰
                    search_results = self.search_engine.search_web(search_query, max_results=8)
                    
                    if search_results:
                        # 3. æ€»ç»“æœç´¢ç»“æœ
                        search_summary = self.search_engine.summarize_search_results(
                            search_query, 
                            search_results
                        )
                        
                        # ç¼“å­˜ç»“æœ
                        self.search_cache[search_query] = {
                            'summary': search_summary,
                            'results': search_results
                        }
                        print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} æ¡ç»“æœ")
                    else:
                        search_summary = "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
                        search_results = []
                        print("âŒ æœç´¢æ— ç»“æœ")
                
                # 4. å¢å¼ºç³»ç»Ÿæç¤ºè¯
                enhanced_context = self.search_engine.enhance_context(
                    user_message,
                    character['name'],
                    search_summary
                )
                
                system_prompt = f"{system_prompt}\n\n{enhanced_context}"
                
                result['search_performed'] = True
                result['search_query'] = search_query
                result['search_summary'] = search_summary
                result['search_results'] = search_results
        
        # 5. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        messages.extend(conversation_history)
        messages.append({"role": "user", "content": user_message})
        
        # 6. è°ƒç”¨GPTç”Ÿæˆå›å¤
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            result['response'] = response.choices[0].message.content
            result['tokens_used'] = response.usage.total_tokens
            
            # è®¡ç®—è´¹ç”¨ï¼ˆgpt-4o-caå®šä»·ï¼‰
            prompt_tokens = response.usage.prompt_tokens
            completion_tokens = response.usage.completion_tokens
            result['cost'] = (prompt_tokens * 0.000005 + 
                            completion_tokens * 0.000015)
            
        except Exception as e:
            print(f"GPTè°ƒç”¨å¤±è´¥: {e}")
            result['response'] = f"æŠ±æ­‰ï¼Œå›å¤ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
        
        return result

